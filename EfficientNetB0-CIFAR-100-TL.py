# -*- coding: utf-8 -*-
"""EE992_v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dDO-kaPh6dr_9zzvBhCcLACN217Qi0jl
"""

# Imports
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from datetime import datetime
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Dropout,BatchNormalization,GlobalAveragePooling2D
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
#from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.efficientnet import EfficientNetB0

# Load in cifar 100 dataset
cifar100 = tf.keras.datasets.cifar100
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')

# Normaise
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# One hot encoding labels
y_train = to_categorical(y_train, num_classes = 100)
y_test = to_categorical(y_test, num_classes = 100)

# Split 80/20
X_train,X_val,y_train,y_val = train_test_split(X_train, y_train, test_size = 0.2)

# Data Augmentation
train_datagen = ImageDataGenerator(
        rotation_range = 20,
        zoom_range = 0.2,
        width_shift_range = 0.2,
        height_shift_range = 0.2,
        shear_range = 0.2,
        vertical_flip = False,
        horizontal_flip = True,
        fill_mode = 'nearest'
        )
train_datagen.fit(X_train)

# Lr scheduler
lr_scheduler = ReduceLROnPlateau(
    monitor='val_accuracy',
    patience=5,
    verbose=1,
    factor=0.5,
    min_lr=1e-6)

# Early Stopping
early_stopping = EarlyStopping(
    monitor="val_loss", patience=10, restore_best_weights=True, verbose=1
)

# Load in ResNet 50
"""
resnet_model = ResNet50(
    include_top = False,
    weights = 'imagenet',
    input_shape = (224,224,3)
)

for layer in resnet_model.layers:
    if isinstance(layer, BatchNormalization):
        layer.trainable = True
    else:
        layer.trainable = False
"""
# Load EfficientNetB0
efficientnet_model = EfficientNetB0(
    include_top=False,
    weights='imagenet',
    input_shape=(224, 224, 3)
)

for layer in efficientnet_model.layers:
    if isinstance(layer, BatchNormalization):
        layer.trainable = True
    else:
        layer.trainable = False

# Build our model
model = tf.keras.models.Sequential([
    UpSampling2D(size=(7, 7), interpolation='bilinear'),
    #resnet_model,
    efficientnet_model,
    GlobalAveragePooling2D(),
    Dropout(0.4),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.4),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.4),
    Dense(100, activation='softmax')
])

# Compile Model
model.compile(
    optimizer = tf.keras.optimizers.SGD(learning_rate=5e-3, momentum=0.9),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fit model
history=model.fit(
    train_datagen.flow(X_train, y_train, batch_size = 128),
    validation_data = (X_val, y_val),
    epochs = 200,
    verbose = 1,
    callbacks = [lr_scheduler, early_stopping]
)

model.save('EfficientNet_v1.keras')
model.save('EfficientNet_v1.h5')

import matplotlib.pyplot as plt

# Function to plot and save loss & accuracy curves
def plot_training_curves(history, save_path="training_curves_EN_1.png"):
    # Extract data from history
    loss = history.history['loss']
    val_loss = history.history.get('val_loss')  # Check if validation loss exists
    acc = history.history.get('accuracy') or history.history.get('acc')  # Handle different key names
    val_acc = history.history.get('val_accuracy') or history.history.get('val_acc')

    epochs = range(1, len(loss) + 1)

    # Create a figure
    plt.figure(figsize=(12, 5))

    # Plot Loss Curve
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, label='Training Loss')
    if val_loss:
        plt.plot(epochs, val_loss, label='Validation Loss', linestyle="--")
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training & Validation Loss')
    plt.legend()

    # Plot Accuracy Curve
    plt.subplot(1, 2, 2)
    if acc:  # Check if accuracy data is available
        plt.plot(epochs, acc, label='Training Accuracy')
        if val_acc:
            plt.plot(epochs, val_acc, label='Validation Accuracy', linestyle="--")
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.title('Training & Validation Accuracy')
        plt.legend()

    # Save the figure
    plt.savefig(save_path, dpi=300)
    plt.show()
    print(f"Plot saved as {save_path}")

# Example usage after training
plot_training_curves(history)